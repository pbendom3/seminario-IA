[[./imagenes/seminario21.PNG]]

* Ética en el uso de la IA.
[[./imagenes/ia_etica.png]]

** Índice
    1. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#1-implicaciones-%C3%A9ticas-y-sociales-de-los-sistemas-de-ia][Implicaciones éticas y sociales de los sistemas de IA.]]
    2. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#2-sora-ia-el-motor-de-inteligencia-artificial-capaz-de-generar-v%C3%ADdeo-realista][Sora IA, el motor de inteligencia artificial capaz de generar vídeo realista.]]
    3. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#3-herramientas-asistidas-por-ia-que-se-utilizan-para-crear-y-distribuir-informaci%C3%B3n--tanto-informaci%C3%B3n-objetiva-como-desinformaci%C3%B3n-bulos-][Herramientas asistidas por IA que se utilizan para crear y distribuir información -tanto información objetiva como desinformación (bulos)-.]]
    4. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#4-introducci%C3%B3n-al-sesgo-con-moralmachine][Introducción al sesgo con moralmachine.]] 
    5. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#5-documental-sesgo-codificado-2020-netflix][Documental: Sesgo Codificado (2020, NETFLIX).]] 
   
** Referencias
- [[https://formacion.intef.es/aulaenabierto/mod/book/view.php?id=5073][INTEF - Ética en la inteligencia artificial]]
- [[https://www.youtube.com/watch?v=SPBn9gwgIsI&t=95s][Vídeo sobre Sora IA]] 
- [[https://www.moralmachine.net/hl/es][Acceso a Moral Machine]]
- [[https://www.netflix.com/es/title/81328723][Documental: Sesgo Codificado (2020, NETFLIX)]] 
- [[https://maldita.es/malditatecnologia/20241230/uso-2024-inteligencia-artificial-bulos-desinformar/][Cómo se ha usado en 2024 la inteligencia artificial para difundir bulos y desinformar]]

** 1. Implicaciones éticas y sociales de los sistemas de IA


** 2. Sora IA, el motor de inteligencia artificial capaz de generar vídeo realista

[[https://sora.com/][Sora]] es el modelo de IA generativa de texto a vídeo de OpenAI. Esto significa que tú escribes un texto y él crea un vídeo que coincide con la descripción del texto. Aquí tienes unos ejemplos:

[[https://www.youtube.com/watch?v=SPBn9gwgIsI&t=95s][./imagenes/sora.PNG]] 

Sora está disponible en la mayor parte del mundo, excepto en la mayoría de países de Europa y el Reino Unido. En España todavía no tenemos acceso, pero como alternativa podemos probar:

- Pika
- Runway -- https://runwayml.com/ 

[[./gif/erasmus.mp4][./gif/erasmus.jpeg]] 

[[./gif/erasmus.mp4]]


*** Los riesgos de Sora

- Generación de contenidos nocivos

Sin barreras de protección, Sora puede generar contenidos desagradables o inapropiados, como vídeos con violencia, gore, material sexual explícito, representaciones despectivas de grupos de personas y otras imágenes de odio, así como la promoción o glorificación de actividades ilegales.

Lo que constituye contenido inapropiado varía mucho en función del usuario (piensa en un niño que utiliza Sora frente a un adulto) y del contexto de la generación del vídeo (un vídeo que advierte sobre los peligros de los fuegos artificiales podría convertirse fácilmente en sangriento de forma educativa).

- Desinformación

Según los vídeos de ejemplo compartidos por OpenAI, uno de los puntos fuertes de Sora es su capacidad para crear escenas fantásticas que no podrían existir en la vida real. Esta fuerza también hace posible crear vídeos "deepfake" en los que personas o situaciones reales se transforman en algo que no es verdad.

Cuando este contenido se presenta como verdad, ya sea accidentalmente (desinformación) o deliberadamente (desinformación), puede causar problemas.

Como escribió [[https://www.linkedin.com/pulse/navigating-ai-impact-elections-2024-digidiplomacy-icdhe/][Eske Montoya Martínez van Egerschot, Jefa de Gobernanza y Ética de la IA en DigiDiplomacy]], "la IA está remodelando las estrategias de campaña, la participación de los votantes y el propio tejido de la integridad electoral".

Los vídeos de IA convincentes pero falsos de políticos o adversarios de políticos tienen el poder de "difundir estratégicamente narrativas falsas y acosar a fuentes legítimas, con el objetivo de socavar la confianza en las instituciones públicas y fomentar la animadversión hacia diversas naciones y grupos de personas".

En un año con muchas elecciones importantes, desde Taiwán hasta la India y Estados Unidos, esto tiene amplias consecuencias.

- Prejuicios y estereotipos

Como ya hemos venido comentando durante las sesiones, el resultado de los modelos generativos de IA depende en gran medida de los datos con los que se han entrenado. Eso significa que los sesgos o estereotipos culturales en los datos de entrenamiento pueden provocar los mismos problemas en los vídeos resultantes. Como [[https://www.datacamp.com/es/podcast/fighting-for-algorithmic-justice-with-dr-joy-buolamwini-artist-in-chief-and-president-of-the-algorithmic-justice-league][Joy Buolamwini expuso en el episodio Luchando por la Justicia Algorítmica de DataFramed]], los sesgos en las imágenes pueden tener graves consecuencias en la actuación policial.


** 3. Herramientas asistidas por IA que se utilizan para crear y distribuir información -tanto información objetiva como desinformación (bulos)-


** 4. Introducción al sesgo con moralmachine


** 5. Documental: Sesgo Codificado (2020, NETFLIX)




