[[./imagenes/seminario21.PNG]]

* 칄tica en el uso de la IA.
[[./imagenes/ia_etica.png]]

** 칈ndice
    1. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#1-implicaciones-%C3%A9ticas-y-sociales-de-los-sistemas-de-ia][Implicaciones 칠ticas y sociales de los sistemas de IA.]]
    2. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#2-sora-ia-el-motor-de-inteligencia-artificial-capaz-de-generar-v%C3%ADdeo-realista][Sora IA, el motor de inteligencia artificial capaz de generar v칤deo realista.]]
    3. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#3-herramientas-asistidas-por-ia-que-se-utilizan-para-crear-y-distribuir-informaci%C3%B3n--tanto-informaci%C3%B3n-objetiva-como-desinformaci%C3%B3n-bulos-][Herramientas asistidas por IA que se utilizan para crear y distribuir informaci칩n -tanto informaci칩n objetiva como desinformaci칩n (bulos)-.]]
    4. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#4-introducci%C3%B3n-al-sesgo-con-moralmachine][Introducci칩n al sesgo con moralmachine.]] 
    5. [[https://github.com/pbendom3/seminario-IA/blob/main/sesion-2.org#5-documental-sesgo-codificado-2020-netflix][Documental: Sesgo Codificado (2020, NETFLIX).]] 
   
** Referencias
- [[https://formacion.intef.es/aulaenabierto/mod/book/view.php?id=5073][INTEF - 칄tica en la inteligencia artificial]]
- [[https://www.youtube.com/watch?v=SPBn9gwgIsI&t=95s][V칤deo sobre Sora IA]] 
- [[https://www.moralmachine.net/hl/es][Acceso a Moral Machine]]
- [[https://www.netflix.com/es/title/81328723][Documental: Sesgo Codificado (2020, NETFLIX)]] 
- [[https://maldita.es/malditatecnologia/20241230/uso-2024-inteligencia-artificial-bulos-desinformar/][C칩mo se ha usado en 2024 la inteligencia artificial para difundir bulos y desinformar]]

** 1. Implicaciones 칠ticas y sociales de los sistemas de IA


** 2. Sora IA, el motor de inteligencia artificial capaz de generar v칤deo realista

[[https://sora.com/][Sora]] es el modelo de IA generativa de texto a v칤deo de OpenAI. Esto significa que t칰 escribes un texto y 칠l crea un v칤deo que coincide con la descripci칩n del texto. Aqu칤 tienes unos ejemplos:

[[https://www.youtube.com/watch?v=SPBn9gwgIsI&t=95s][./imagenes/sora.PNG]] 

Sora est치 disponible en la mayor parte del mundo, excepto en la mayor칤a de pa칤ses de Europa y el Reino Unido. En Espa침a todav칤a no tenemos acceso, pero como alternativa podemos probar:

- Pika
- Runway -- https://runwayml.com/ 

[[./gif/erasmus.mp4][./gif/erasmus.jpeg]] 

[[./gif/erasmus.mp4]]


*** Los riesgos de Sora

- *Generaci칩n de contenidos nocivos*

Sin barreras de protecci칩n, Sora puede generar contenidos desagradables o inapropiados, como v칤deos con violencia, gore, material sexual expl칤cito, representaciones despectivas de grupos de personas y otras im치genes de odio, as칤 como la promoci칩n o glorificaci칩n de actividades ilegales.

Lo que constituye contenido inapropiado var칤a mucho en funci칩n del usuario (piensa en un ni침o que utiliza Sora frente a un adulto) y del contexto de la generaci칩n del v칤deo (un v칤deo que advierte sobre los peligros de los fuegos artificiales podr칤a convertirse f치cilmente en sangriento de forma educativa).

- *Desinformaci칩n*

Seg칰n los v칤deos de ejemplo compartidos por OpenAI, uno de los puntos fuertes de Sora es su capacidad para crear escenas fant치sticas que no podr칤an existir en la vida real. Esta fuerza tambi칠n hace posible crear v칤deos "deepfake" en los que personas o situaciones reales se transforman en algo que no es verdad.

Cuando este contenido se presenta como verdad, ya sea accidentalmente (desinformaci칩n) o deliberadamente (desinformaci칩n), puede causar problemas.

Como escribi칩 [[https://www.linkedin.com/pulse/navigating-ai-impact-elections-2024-digidiplomacy-icdhe/][Eske Montoya Mart칤nez van Egerschot, Jefa de Gobernanza y 칄tica de la IA en DigiDiplomacy]], "la IA est치 remodelando las estrategias de campa침a, la participaci칩n de los votantes y el propio tejido de la integridad electoral".

Los v칤deos de IA convincentes pero falsos de pol칤ticos o adversarios de pol칤ticos tienen el poder de "difundir estrat칠gicamente narrativas falsas y acosar a fuentes leg칤timas, con el objetivo de socavar la confianza en las instituciones p칰blicas y fomentar la animadversi칩n hacia diversas naciones y grupos de personas".

En un a침o con muchas elecciones importantes, desde Taiw치n hasta la India y Estados Unidos, esto tiene amplias consecuencias.

- *Prejuicios y estereotipos*

Como ya hemos venido comentando durante las sesiones, el resultado de los modelos generativos de IA depende en gran medida de los datos con los que se han entrenado. Eso significa que los sesgos o estereotipos culturales en los datos de entrenamiento pueden provocar los mismos problemas en los v칤deos resultantes. Como [[https://www.datacamp.com/es/podcast/fighting-for-algorithmic-justice-with-dr-joy-buolamwini-artist-in-chief-and-president-of-the-algorithmic-justice-league][Joy Buolamwini expuso en el episodio Luchando por la Justicia Algor칤tmica de DataFramed]], los sesgos en las im치genes pueden tener graves consecuencias en la actuaci칩n policial.


** 3. Herramientas asistidas por IA que se utilizan para crear y distribuir informaci칩n -tanto informaci칩n objetiva como desinformaci칩n (bulos)-


** 4. Introducci칩n al sesgo con moralmachine

Dir칤gete al siguiente sitio web, donde vas a entrenar a un coche autom치tico para tomar una serie de decisiones: https://www.moralmachine.net/

[[./imagenes/moral.PNG]]

丘멆잺 *AVISO*: lamentablemente, algunas decisiones ser치n poco 칠ticas...游땬丘멆잺

** 5. Documental: Sesgo Codificado (2020, NETFLIX)

[[https://www.netflix.com/es/title/81328723][Este documental]] investiga errores en los algoritmos despu칠s de que Joy Buolamwini, investigadora del MIT, revelara fallos en la tecnolog칤a de reconocimiento facial.

[[./imagenes/sesgo2.jpeg]]

En concreto, Joy se da cuenta de que un programa de reconocimiento facial no distingue ni identifica su rostro como el de una persona cuantificable para su base de datos. Pero s칤 lo hace cuando se coloca una m치scara neutra... y blanca.

Es el punto de partida de un documental que picotea en much칤simos temas, todos a partir de la arbitrariedad y falta de 칠tica con la que los algoritmos recogen informaci칩n para dar forma a sus bases de datos y los conocimientos con los que van engordando distintas IAs. Una arbitrariedad que toma forma a partir de prejuicios que todos tenemos y que hacen que, por ejemplo, y como dice uno de los participantes en este interesante documental, *el racismo se mecanice y se replique*.





